{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot using TF",
      "provenance": [],
      "collapsed_sections": [
        "Zi-1uyTYyAEf"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMDJ3GIhE+Jtwsa1BFM3J6w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanM-18/Intermediate-Deep-Learning-projects-using-Tensorflow-Keras/blob/main/Chatbot_using_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwyVNITE6XR8",
        "outputId": "de8b82d1-da0c-4456-e9fb-b33a6ff3ba2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-524be291-631d-3b00-57cf-8e0d9abfd7b1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing the required libraries and downloading the dataset from Kaggle"
      ],
      "metadata": {
        "id": "cLFhE58jyDU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H_MvUPRuZCr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import random\n",
        "import time\n",
        "import string\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content\""
      ],
      "metadata": {
        "id": "bcuSxdvpxBEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 \"/content/kaggle.json\""
      ],
      "metadata": {
        "id": "4wnM4UpOxuwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tovarischsukhov/southparklines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgQgDt_Ixtjn",
        "outputId": "c5ae9e56-41df-4fab-e4ba-ed32dea7ceb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading southparklines.zip to /content\n",
            "\r  0% 0.00/1.81M [00:00<?, ?B/s]\n",
            "\r100% 1.81M/1.81M [00:00<00:00, 63.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/southparklines.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "RFxq8at3x0Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading the dataset and performing some basic EDA "
      ],
      "metadata": {
        "id": "Zi-1uyTYyAEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/All-seasons.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uneppcCyyaoj",
        "outputId": "97401d0f-f9d5-42d8-aab8-1ee4541fafaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22507f1c-877f-46a9-93e4-4d85bd5304a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Episode</th>\n",
              "      <th>Character</th>\n",
              "      <th>Line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>You guys, you guys! Chef is going away. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Kyle</td>\n",
              "      <td>Going away? For how long?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>Forever.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Chef</td>\n",
              "      <td>I'm sorry boys.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>Stan</td>\n",
              "      <td>Chef said he's been bored, so he joining a gro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22507f1c-877f-46a9-93e4-4d85bd5304a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22507f1c-877f-46a9-93e4-4d85bd5304a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22507f1c-877f-46a9-93e4-4d85bd5304a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Season Episode Character                                               Line\n",
              "0     10       1      Stan         You guys, you guys! Chef is going away. \\n\n",
              "1     10       1      Kyle                        Going away? For how long?\\n\n",
              "2     10       1      Stan                                         Forever.\\n\n",
              "3     10       1      Chef                                  I'm sorry boys.\\n\n",
              "4     10       1      Stan  Chef said he's been bored, so he joining a gro..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93HAOxooyrBj",
        "outputId": "f0e59571-15d1-4bd8-a186-7a988e952795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70896 entries, 0 to 70895\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Season     70896 non-null  object\n",
            " 1   Episode    70896 non-null  object\n",
            " 2   Character  70896 non-null  object\n",
            " 3   Line       70896 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 2.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [x.lower() for x in df.columns]"
      ],
      "metadata": {
        "id": "9aGd1wjnzXj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = df.line.tolist()"
      ],
      "metadata": {
        "id": "AKVKGlf29sBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues[105:145]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yAqaISI9tj7",
        "outputId": "c5df8969-ae0f-40bc-abb9-d47f8489b2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Well look: he spent the last three months with that adventurers' club. Maybe they know what happened to him.\\n\",\n",
              " '(Yeah! I think...)\\n',\n",
              " 'Yeah!\\n',\n",
              " 'All right, come on guys!\\n',\n",
              " \"Hey you guys, you know what they call a Jewish woman's boobs? Jewbs. \\n\",\n",
              " 'May I help you.\\n',\n",
              " 'Ahh, hi, can we speak to the head guy or something?\\n',\n",
              " 'Right this way. \\n',\n",
              " \"Now, the upper rim of Kilimanjaro should be quite a trek, and so we'll need to have a-\\n\",\n",
              " 'Excuse me, sir. These boys wanted to speak with you.\\n',\n",
              " \"Ahh yes, splendid! Good afternoon, lads! I'm Head Adventurer William P. Connolly, Esquire! Welcome, to the Super Adventure Club!\\n\",\n",
              " 'Tally ho!\\n',\n",
              " 'Indeed!\\n',\n",
              " 'Uh, hi. Our friend joined your club a while back, and now he wants to molest kids. \\n',\n",
              " \"What? Well... well yes, of course! That's what the Super Adventure Club does!\\n\",\n",
              " '...Huh?\\n',\n",
              " 'We travel the world and have sex with children!\\n',\n",
              " 'Yes, what else would we do?\\n',\n",
              " 'Well, we thought you went exploring and like, hunting and stuff!\\n',\n",
              " \"Noo, no, that's the Adventure Club. We're the Super Adventure Club!  Next week, we'll be heading to the outer banks of the Amazon, where we will make camp and have sex with children of the Ugani tribe, then it's off to the mighty Himalayas, where we will climb K-2, and molest several Tibetan children on the east summit.\\n\",\n",
              " '...Dude!\\n',\n",
              " \"I know, but it gets even better! From there we will kayak to the fruitful banks of the Mele River in Africa, where the secret and mysterious Hanimi people have children who have never seen a white man's erect penis. Of course, we're always looking for kids to have sex with on the plane rides over to these places, so how would you ALL like to join the Super Adventure Club!\\n\",\n",
              " 'NO!!\\n',\n",
              " 'No? Oh really? Perhaps I should ask you again?  How would you like to join the Super Adventure Club? \\n',\n",
              " 'No! \\n',\n",
              " 'Dude, what are you doing?!\\n',\n",
              " \"Oh well, it doesn't work on everybody.  Well, so long then.\\n\",\n",
              " 'Just what the hell is that thing?!\\n',\n",
              " \"What? What thing? I don't see anything.\\n\",\n",
              " 'HA! I knew it!\\n',\n",
              " 'Knew what?\\n',\n",
              " \"The reason Chef has been saying those terrible things about us is because he's been brainwashed! By this- fruity little club!\\n\",\n",
              " 'Oh, son of a bitch!\\n',\n",
              " \"Come on, children. Let's all go home and make love.\\n\",\n",
              " \"You need to see a psychiatrist, Chef. It's for your own good.\\n\",\n",
              " 'I just like to make love up your butt.\\n',\n",
              " 'Oh my God!\\n',\n",
              " 'Mr. Chef, is it?\\n',\n",
              " 'All right, come on. \\n',\n",
              " \"Hello, I'm Dr. Neeland. What can I do for you today?\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text preprocessing"
      ],
      "metadata": {
        "id": "iHTOgoTU-vU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "\n",
        "  text = text.lower()\n",
        "\n",
        "  text = re.sub(r\"\\n\", \"\", text)\n",
        "  text = re.sub(r\"[-()]\", \"\", text)\n",
        "  text = re.sub(r\"\\.\", \" .\", text)\n",
        "  text = re.sub(r\"\\!\", \" !\", text)\n",
        "  text = re.sub(r\"\\,\", \" ,\", text)\n",
        "  text = re.sub(r\"\\?\", \" ?\", text)\n",
        "  text = re.sub(r\"-\", \" \", text)\n",
        "  text = re.sub(r\":\", \"\", text)\n",
        "  text = re.sub(r\"let's\", \"let us\", text)\n",
        "  text = re.sub(r\"ma'am\", \"madam\", text)\n",
        "  text = re.sub(r\"i'm\", \"i am\", text)\n",
        "  text = re.sub(r\"that's\", \"that is\", text)\n",
        "  text = re.sub(r\"what's\", \"what is\", text)\n",
        "  text = re.sub(r\"he's\", \"he is\", text)\n",
        "  text = re.sub(r\"she's\", \"she is\", text)\n",
        "  text = re.sub(r\"it's\", \"it is\", text)\n",
        "  text = re.sub(r\"won't\", \"will not\", text)\n",
        "  text = re.sub(r\"can't\", \"cannot\", text)\n",
        "  text = re.sub(r\"don't\", \"do not\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"n't\", \" not\", text)\n",
        "  text = re.sub(r\"n'\", \"ng\", text)\n",
        "  text = re.sub(r\"ohhhhhh\", \"oh\", text)\n",
        "  text = re.sub(r\"uh\", \"\", text)\n",
        "  text = re.sub(r\"ohh\", \"oh\", text)\n",
        "  text = re.sub(r\"ohhh\", \"oh\", text)\n",
        "  text = re.sub(r\"ohhhh\", \"oh\", text)\n",
        "  text = re.sub(r\"ohhhhh\", \"oh\", text)\n",
        "  text = re.sub(r\"ahh\", \"\", text)\n",
        "  text = re.sub(r\"ah\", \"\", text)\n",
        "  text = re.sub(r\"\\xa0\", \"\", text)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "kPnXDPIs-0Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = []\n",
        "\n",
        "for line in dialogues:\n",
        "  text.append(clean_text(line))"
      ],
      "metadata": {
        "id": "QKRXNPm3B74A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBNi-q-gCN4E",
        "outputId": "7e0eb1f7-2fbe-4d48-ea95-b2602c939ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you guys , you guys ! chef is going away . ',\n",
              " 'going away ? for how long ?',\n",
              " 'forever .',\n",
              " 'i am sorry boys .',\n",
              " 'chef said he is been bored , so he joining a group called the super adventure club . ',\n",
              " 'wow !',\n",
              " 'chef ? ? what kind of questions do you think adventuring around the world is gonna answer ? !',\n",
              " 'what is the meaning of life ? why are we here ?',\n",
              " 'i hope you are making the right choice .',\n",
              " 'i am gonna miss him .  i am gonna miss chef and i . . .and i do not know how to tell him ! ']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(25):\n",
        "  random_text = random.randint(0, len(text))\n",
        "  print(text[random_text])\n",
        "  print(\"-\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkW8DKdgCRDm",
        "outputId": "da21b0dd-b6ac-4afc-a76b-f02a81964352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buddha , will you lay off that stuff already ? ! it is getting to be a problem .\n",
            "----------------------------------------\n",
            "what do you know ?\n",
            "----------------------------------------\n",
            "my name is sid greenfield . i am the director from los angeles for america is most wanted .\n",
            "----------------------------------------\n",
            "okay , if you guys just wait here a sec we are gonna have a quickening with the council of geniuses . see what we can do for you .\n",
            "----------------------------------------\n",
            "i heard it , too .\n",
            "----------------------------------------\n",
            "awwww \n",
            "----------------------------------------\n",
            "i am not playing around , kyle ! if we survive this , i do not intend to live in poverty ! give me your jew gold now !\n",
            "----------------------------------------\n",
            "you are welcome ! ! now leave us alone ! !  my fellow gingers ! i envision a world in which there is no hate ! a world where everyone is ginger ! and so , we must gather together every child who is not ginger , and exterminate them !\n",
            "----------------------------------------\n",
            "it is been four hours now , and tom cruise still will not come out of the closet . hundreds of onlookers here have gathered here in hopes that the celebrity will finally give in .\n",
            "----------------------------------------\n",
            "h ?\n",
            "----------------------------------------\n",
            "yes , there is something that you all need to know . the truth about the red cow . we have all been  so sorry , hang on .  hello ?\n",
            "----------------------------------------\n",
            "the necronomicon ?\n",
            "----------------------------------------\n",
            "righto . pip . righto .\n",
            "----------------------------------------\n",
            "because if those people all think you are the reincarnation of l . ron hubbard , then they will all buy your new writings , and you and i together will make three million dollars !\n",
            "----------------------------------------\n",
            "oh who cares about some oil spill environment crap ? !\n",
            "----------------------------------------\n",
            "then , let us do token is report on how global warming is going to kill everyone in the fifth grade .\n",
            "----------------------------------------\n",
            "liver medicine ?\n",
            "----------------------------------------\n",
            "well , so then wwe will recruit us and not them .\n",
            "----------------------------------------\n",
            "there is only one answer eat eric roberts . \n",
            "----------------------------------------\n",
            "you just love pushing me around ! is that what you wanna do , kyle ? ! kick the baby ? ! well alrighty bro ! come on , kyle ! kick the baby ! come on bro ! kick the fucking baby ! let us see you try it , wuss !\n",
            "----------------------------------------\n",
            "i am not \"jel\" , and i happen to be the biggest feminist at this school !\n",
            "----------------------------------------\n",
            "ye , it is ms . choksondik alright .\n",
            "----------------------------------------\n",
            "you know that big statue in the town square of pioneer john wesley powell ? i snuck over there with a hacksaw and  , and i cut off his head !  haa , ye !\n",
            "----------------------------------------\n",
            "do not , do not act for me , stan ! really ? ! because every minute i am watching this video become less about awareness and more about you !\n",
            "----------------------------------------\n",
            "you know what these guys look like to me ? a bunch of winners !\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O-j7J2NtDRPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_lengths = []\n",
        "\n",
        "for line in text:\n",
        "  sentences_lengths.append(len(line.split()))\n",
        "\n",
        "lengths_df = pd.DataFrame({\"sent_length\": sentences_lengths})\n",
        "lengths_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygolg4NdFRNW",
        "outputId": "3f1e259e-51bb-4002-e436-88977fdf3197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d9205e40-6d50-4275-bc86-51718426626d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>70896.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>15.005938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.201729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>398.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9205e40-6d50-4275-bc86-51718426626d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9205e40-6d50-4275-bc86-51718426626d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9205e40-6d50-4275-bc86-51718426626d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        sent_length\n",
              "count  70896.000000\n",
              "mean      15.005938\n",
              "std       16.201729\n",
              "min        0.000000\n",
              "25%        6.000000\n",
              "50%       11.000000\n",
              "75%       19.000000\n",
              "max      398.000000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[lengths_df.idxmax().tolist()[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMOtCIfXFRfS",
        "outputId": "7eac38a7-b7e6-4724-8392-f1d84f254ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"okay , first of all , i am not aquaman , i am a recovering . . . gay fish . yes , i have met aquaman . i have hung out with aquaman . but the only thing i have in common with aquaman anymore is my love for the sea .now !there have been malicious rumors , started at this elementary school , that my beautiful fiancée is a hobbit . that is not funny , and it is not true .alright ? ! yes , kim is heavier than most of her pictures show her to be . yes , she gets her hair lasered off her body . yes , she has a friend named gandalf who happens to be a wizard .i am sorry , excuse me a minute .bitch , how are you not a hobbit again ? ye . ye ye ye right . rightrightrightrightright , ye . okay . yep . yep . let me get okay . yep , i got it . okay , love you too .okay , if my fiancée kim… is… a hobbit , then how come… it  how c then , okay , if she is a hobbit , then how come she do not live in a hole in the ground ? boooooom ! all y'all just got lit up , cuz ! she do not live in no hole in the ground , she lives in a bigass mansion , with me , in her room , that is slightly below ground ! so , you can… she , she is sexy , and womanly , and she smokes a pipe . she can blow them rings that go up over her head , and… hold up .bitch , you not a hobbit , right ?  . . . no , i know , you just , you smoke that long pipe sometimes when you sit by the fire . . . oh it is a oh , okay . got it , got it what do you call it ? yep . yep , got it . okay . yep , love you too .that is not a hobbit pipe , for your information ! it is a personal oral humidifier to keep all the wrinkles around her mouth from showing . so ha , all you haters , ha !\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(sentences_lengths, 90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDX4td5FFRjU",
        "outputId": "dafe98bc-4b12-4413-a8c5-decb7d886577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.percentile(sentences_lengths, 95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrfSlx75FRnA",
        "outputId": "15271bc3-3006-4575-b3dd-5ce2e77e3348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N56UbB38FRqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = np.percentile(sentences_lengths, 95)\n",
        "\n",
        "short_text = []\n",
        "\n",
        "for line in text:\n",
        "  if len(line.split()) <= max_len:\n",
        "    short_text.append(line)"
      ],
      "metadata": {
        "id": "XoNY6LQhRyQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text), len(short_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFRnc2ETSJIx",
        "outputId": "a21898a6-b9d9-4d37-e7b6-0b1105e27769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70896, 67522)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {}\n",
        "\n",
        "for line in short_text:\n",
        "  for word in line.split():\n",
        "    if word not in vocabulary:\n",
        "      vocabulary[word] = 1\n",
        "    else:\n",
        "      vocabulary[word] += 1"
      ],
      "metadata": {
        "id": "dM4GfFv4SK4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijmAwP4BSOdi",
        "outputId": "c033d04d-0ae6-4bd5-a11f-d56165c35a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25385"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 3\n",
        "count = 0\n",
        "\n",
        "for key, value in vocabulary.items():\n",
        "  if value >= threshold:\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "QEIcg8_pSo-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count, len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzmGNXhlTEhC",
        "outputId": "8967e8d6-6dad-41bd-ee49-976010ee8c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9079, 25385)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6jgAMpoGTGT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vocab_to_int = {}\n",
        "\n",
        "word_count_source = 0\n",
        "for key, value in vocabulary.items():\n",
        "  if value >= threshold:\n",
        "    source_vocab_to_int[key] = word_count_source\n",
        "    word_count_source += 1\n",
        "\n",
        "target_vocab_to_int = {}\n",
        "\n",
        "word_count_target = 0\n",
        "for key, value in vocabulary.items():\n",
        "  if value >= threshold:\n",
        "    target_vocab_to_int[key] = word_count_target\n",
        "    word_count_target += 1"
      ],
      "metadata": {
        "id": "H18iJh8xUE0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_vocab_to_int), len(target_vocab_to_int), word_count_source, word_count_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InGPAgiZUE-O",
        "outputId": "eacfe670-5f51-4cc1-e1f6-a6c1bb1da327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9079, 9079, 9079, 9079)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h5CDl2b4U3eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text = short_text[:-1]\n",
        "target_text = short_text[1:]"
      ],
      "metadata": {
        "id": "kIaSNmSbVHz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text[-1], target_text[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdxLcE6aXpNz",
        "outputId": "8a328396-743b-4efd-d128-aa2ac68e1d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('right right . does vodka count ?', 'dad !')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_text[0], target_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_NfJ4HAX2wi",
        "outputId": "35dfcd9b-99c4-4f20-b1b1-f3f5a3f72051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('you guys , you guys ! chef is going away . ', 'going away ? for how long ?')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_text[1], target_text[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu4tjIl7X6Lf",
        "outputId": "f78bc165-9266-40a2-b663-ac2aa556f708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('going away ? for how long ?', 'forever .')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z8Yu8rPaYCTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [\"<PAD>\", \"<EOS>\", \"<SOS>\", \"<UNK>\"]\n",
        "\n",
        "for token in tokens:\n",
        "  source_vocab_to_int[token] = len(source_vocab_to_int) + 1\n",
        "  target_vocab_to_int[token] = len(target_vocab_to_int) + 1"
      ],
      "metadata": {
        "id": "NF-OtXcyYM8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_vocab_to_int), len(target_vocab_to_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c5NPkzCddIi",
        "outputId": "3534ac08-38b1-452b-e183-551ae120fa86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9083, 9083)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F8MpLK9Tdipx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_int_to_vocab = {y:x for x,y in source_vocab_to_int.items()}\n",
        "target_int_to_vocab = {y:x for x,y in target_vocab_to_int.items()}"
      ],
      "metadata": {
        "id": "Qk3YA3YUdniF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_target_text = []\n",
        "\n",
        "for sentence in range(len(target_text)):\n",
        "  new_sentence = \"<SOS> \" + target_text[sentence] + \" <EOS>\"\n",
        "  modified_target_text.append(new_sentence)"
      ],
      "metadata": {
        "id": "62Qz7Mwqdnmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_target_text[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB4MnwmTdnqJ",
        "outputId": "291ba8ae-71c5-4661-e5e0-b90bd0c34980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> going away ? for how long ? <EOS>',\n",
              " '<SOS> forever . <EOS>',\n",
              " '<SOS> i am sorry boys . <EOS>',\n",
              " '<SOS> chef said he is been bored , so he joining a group called the super adventure club .  <EOS>',\n",
              " '<SOS> wow ! <EOS>',\n",
              " '<SOS> chef ? ? what kind of questions do you think adventuring around the world is gonna answer ? ! <EOS>',\n",
              " '<SOS> what is the meaning of life ? why are we here ? <EOS>',\n",
              " '<SOS> i hope you are making the right choice . <EOS>',\n",
              " '<SOS> i am gonna miss him .  i am gonna miss chef and i . . .and i do not know how to tell him !  <EOS>',\n",
              " '<SOS> dude , how are we gonna go on ? chef was our f . . .fffriend .  <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qD139CkHLUbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_int = []\n",
        "\n",
        "for line in source_text:\n",
        "  sentence = []\n",
        "  for word in line.split():\n",
        "    if word not in source_vocab_to_int:\n",
        "      sentence.append(source_vocab_to_int[\"<UNK>\"])\n",
        "    else:\n",
        "      sentence.append(source_vocab_to_int[word])\n",
        "  \n",
        "  source_int.append(sentence)"
      ],
      "metadata": {
        "id": "STpE_mR9LWx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_int = []\n",
        "\n",
        "for line in modified_target_text:\n",
        "  sentence = [] \n",
        "  for word in line.split():\n",
        "    if word not in target_vocab_to_int:\n",
        "      sentence.append(target_vocab_to_int[\"<UNK>\"])\n",
        "    else:\n",
        "      sentence.append(target_vocab_to_int[word])\n",
        "    \n",
        "  target_int.append(sentence)"
      ],
      "metadata": {
        "id": "erD40UmUMBMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_int[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFRTAHkwMVa2",
        "outputId": "09844b2f-9b6b-4eb2-c92e-457435dbc20c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 0, 1, 3, 4, 5, 6, 7, 8], [6, 7, 9, 10, 11, 12, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_int[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVPeLpNFMW2X",
        "outputId": "5f0bed15-322c-4015-9c6e-2c8bc2347dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9082, 6, 7, 9, 10, 11, 12, 9, 9081], [9082, 13, 8, 9081]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tFdNwDUdMYYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing the data to feed the model"
      ],
      "metadata": {
        "id": "D3Yuy4-LPhuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_input_data = np.zeros((len(source_text), 42, len(source_vocab_to_int)))\n",
        "\n",
        "# encoder_input_data = np.zeros((32, 42, len(source_vocab_to_int)))\n",
        "# decoder_input_data = np.zeros((32, 42, len(target_vocab_to_int)))\n",
        "# decoder_output_data = np.zeros((32, 42, len(target_vocab_to_int)))"
      ],
      "metadata": {
        "id": "BNQnAt_SPmA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text_sample = source_text[:5]\n",
        "target_text_sample = target_text[:5]\n",
        "\n",
        "new_source_dict = {}\n",
        "new_target_dict = {}\n",
        "\n",
        "count_source = 1\n",
        "for sentence in source_text_sample:\n",
        "  for word in sentence.split():\n",
        "    if word not in new_source_dict:\n",
        "      new_source_dict[word] = count_source\n",
        "      count_source += 1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "count_target = 1\n",
        "for sentence in target_text_sample:\n",
        "  for word in sentence.split():\n",
        "    if word not in new_target_dict:\n",
        "      new_target_dict[word] = count_target\n",
        "      count_target += 1\n",
        "    else:\n",
        "      continue"
      ],
      "metadata": {
        "id": "kkpSqSH2QT6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text_sample, target_text_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taemma_7RdH3",
        "outputId": "469b56ce-7dcc-455b-8b44-6d4e68d287a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['you guys , you guys ! chef is going away . ',\n",
              "  'going away ? for how long ?',\n",
              "  'forever .',\n",
              "  'i am sorry boys .',\n",
              "  'chef said he is been bored , so he joining a group called the super adventure club . '],\n",
              " ['going away ? for how long ?',\n",
              "  'forever .',\n",
              "  'i am sorry boys .',\n",
              "  'chef said he is been bored , so he joining a group called the super adventure club . ',\n",
              "  'wow !'])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_source_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSfBkTQpRdEq",
        "outputId": "ef3008fb-25c6-474d-a25a-792b7c229d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 4,\n",
              " ',': 3,\n",
              " '.': 9,\n",
              " '?': 10,\n",
              " 'a': 25,\n",
              " 'adventure': 30,\n",
              " 'am': 16,\n",
              " 'away': 8,\n",
              " 'been': 21,\n",
              " 'bored': 22,\n",
              " 'boys': 18,\n",
              " 'called': 27,\n",
              " 'chef': 5,\n",
              " 'club': 31,\n",
              " 'for': 11,\n",
              " 'forever': 14,\n",
              " 'going': 7,\n",
              " 'group': 26,\n",
              " 'guys': 2,\n",
              " 'he': 20,\n",
              " 'how': 12,\n",
              " 'i': 15,\n",
              " 'is': 6,\n",
              " 'joining': 24,\n",
              " 'long': 13,\n",
              " 'said': 19,\n",
              " 'so': 23,\n",
              " 'sorry': 17,\n",
              " 'super': 29,\n",
              " 'the': 28,\n",
              " 'you': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_target_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGicP2rHRdBB",
        "outputId": "240eb8ec-0d9b-4582-d0e9-3313df8342e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 30,\n",
              " ',': 19,\n",
              " '.': 8,\n",
              " '?': 3,\n",
              " 'a': 22,\n",
              " 'adventure': 27,\n",
              " 'am': 10,\n",
              " 'away': 2,\n",
              " 'been': 17,\n",
              " 'bored': 18,\n",
              " 'boys': 12,\n",
              " 'called': 24,\n",
              " 'chef': 13,\n",
              " 'club': 28,\n",
              " 'for': 4,\n",
              " 'forever': 7,\n",
              " 'going': 1,\n",
              " 'group': 23,\n",
              " 'he': 15,\n",
              " 'how': 5,\n",
              " 'i': 9,\n",
              " 'is': 16,\n",
              " 'joining': 21,\n",
              " 'long': 6,\n",
              " 'said': 14,\n",
              " 'so': 20,\n",
              " 'sorry': 11,\n",
              " 'super': 26,\n",
              " 'the': 25,\n",
              " 'wow': 29}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_sample_source = 0\n",
        "max_len_sample_target = 0\n",
        "\n",
        "for sentence in source_text_sample:\n",
        "  if len(sentence.split()) >= max_len_sample_source:\n",
        "    max_len_sample_source = len(sentence.split())\n",
        "\n",
        "for sentence in target_text_sample:\n",
        "  if len(sentence.split()) >= max_len_sample_target:\n",
        "    max_len_sample_target = len(sentence.split())"
      ],
      "metadata": {
        "id": "a4jRviyjSGSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_sample_source, max_len_sample_target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhmZiieiSsEO",
        "outputId": "5b8ec920-e9f5-4b24-e5e0-cb1ba028a58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_sample = np.zeros((len(source_text_sample), max_len_sample_source, len(new_source_dict)+1))\n",
        "decoder_input_data_sample = np.zeros((len(target_text_sample), max_len_sample_target, len(new_target_dict)+1))\n",
        "decoder_output_data_sample = np.zeros((len(target_text_sample), max_len_sample_target, len(new_target_dict)+1))"
      ],
      "metadata": {
        "id": "SCdnLR-xSCXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KsIgyTj5Rc1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line, (input_line, target_line) in enumerate(zip(source_text_sample, target_text_sample)):\n",
        "\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_line)):\n",
        "        \n",
        "      encoder_input_data_sample[line, timestep, new_source_dict[token]] = 1\n",
        "    \n",
        "    for timestep, token in enumerate(target_line.split()):\n",
        "\n",
        "      decoder_input_data_sample[line, timestep, new_target_dict[token]] = 1\n",
        "      if timestep > 0:\n",
        "          decoder_output_data_sample[line, timestep - 1, new_target_dict[token]] = 1"
      ],
      "metadata": {
        "id": "9iD9d5t0P9yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall(r\"[\\w']+|[^\\s\\w]\", \"hello how are you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9921T4ZY2c0",
        "outputId": "218ee213-85f7-4694-d26a-bd638455c6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'how', 'are', 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_sample[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4hRyt5mIIy4",
        "outputId": "7ff39e8f-bec0-421a-8fbf-0d7344423ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data_sample[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G01uWnRsII6Y",
        "outputId": "72d87b5a-b9b9-43c4-fc18-078a1054b164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_data_sample[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYq4BL7aPm2q",
        "outputId": "fa5f3e24-eabc-42ac-c53b-1ce5608d8739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zA-lkDamPnMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_batches = []\n",
        "decoder_input_data_batches = []\n",
        "decoder_output_data_batches = []"
      ],
      "metadata": {
        "id": "8EhSHHTChAsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_var = 0\n",
        "batches_encoder = 0\n",
        "while count_var <= len(source_text)-1:\n",
        "  encoder_inp = np.zeros((count_var+32, 42, len(source_int_to_vocab)))\n",
        "  encoder_input_data_batches.append(encoder_inp)\n",
        "  count_var += 32\n",
        "  batches_encoder += 1"
      ],
      "metadata": {
        "id": "IadgahOMhAoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QKuwNc-shAmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downsampling the source text and target text and recreating the vocabulary dictionaries "
      ],
      "metadata": {
        "id": "dzYek02thAdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_samples = random.sample(list(range(0, len(source_text))), 5000)"
      ],
      "metadata": {
        "id": "iPJXBrNEhAa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_text_downsampled = []\n",
        "target_text_downsampled = []\n",
        "\n",
        "for x in selected_samples:\n",
        "  source_text_downsampled.append(source_text[x])\n",
        "  target_text_downsampled.append(target_text[x])"
      ],
      "metadata": {
        "id": "_Xvy08vGp9C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_text_downsampled), len(target_text_downsampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2RlmfelqDry",
        "outputId": "8f17dfda-3e2d-4aa1-9880-be8877fe1587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Trying the tokenizer way and making use of the PAD token\n"
      ],
      "metadata": {
        "id": "qkGK7ysjjnQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Preparing the input data for Encoder `(encoder_input_data)`\n",
        "\n",
        "1. tokenizing the sentences in `source_text`\n",
        "2. finding the maximum length for `encoder_input_data`\n",
        "3. **Padding the `tokenized_source_text` to maximum length**\n",
        "4. Finding the vocabulary size for the source text"
      ],
      "metadata": {
        "id": "j_x31xaUlnWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "source_tokenizer.fit_on_texts(source_text_downsampled)\n",
        "tokenized_source_text = source_tokenizer.texts_to_sequences(source_text_downsampled)"
      ],
      "metadata": {
        "id": "M6Rn6pAilnSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_source_text[:3], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMuqYSXXnkka",
        "outputId": "33b8644a-477c-450b-a5cf-7371b80bb434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[164, 1541, 1164, 45, 120, 39, 68, 8, 45, 31, 7, 291, 16, 99, 81, 164, 8, 45], [221, 11, 182, 3, 4, 1542, 182, 18, 4, 1165], [324, 1543, 18, 20, 2466, 2467, 9, 29, 440, 5, 57, 25, 1543, 2468]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_source_text_downsampled = 0\n",
        "\n",
        "for sentence in tokenized_source_text:\n",
        "  if len(sentence) >= max_length_source_text_downsampled:\n",
        "    max_length_source_text_downsampled = len(sentence)"
      ],
      "metadata": {
        "id": "7BYBvK1wlnLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_source_text_downsampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4nAQmCilnIz",
        "outputId": "45cc8929-c660-47dd-a53d-9ac1c04ce523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_source_text_downsampled = keras.preprocessing.sequence.pad_sequences(tokenized_source_text, \n",
        "                                  maxlen=max_length_source_text_downsampled, padding=\"post\")\n",
        "encoder_input_data_ds = np.array(padded_source_text_downsampled)"
      ],
      "metadata": {
        "id": "AVovFWS4oHNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er_M1daLoHKB",
        "outputId": "be651496-dad0-40e1-c71a-c495f19b627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD94BZiRoHG7",
        "outputId": "75af54d4-4b94-43ed-e8a8-22d190030242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 164, 1541, 1164,   45,  120,   39,   68,    8,   45,   31,    7,\n",
              "        291,   16,   99,   81,  164,    8,   45,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_text_downsampled_vocab_dict = source_tokenizer.word_index\n",
        "num_encoder_tokens = len(source_text_downsampled_vocab_dict) + 1"
      ],
      "metadata": {
        "id": "37uDc94QoHC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_encoder_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97eRKlbtoG_t",
        "outputId": "4fc5ba5e-7448-452d-e263-465c7b67dae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5902"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Preparing input data for the decoder `(decoder_input_data)`\n",
        "\n",
        "1. Append `<START>` token at the start of each sentence and `<END>` token at the end of each sentence \n",
        "2. tokenizing the sentence in `target_text`\n",
        "3. finding the maximum length for `decoder_input_data`\n",
        "4. **Padding the `tokenized_target_text` to maximum length**\n",
        "5. Finding the vocbulary size for the target text"
      ],
      "metadata": {
        "id": "cTnkbJoboG8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_target_text_downsampled = []\n",
        "\n",
        "for line in target_text_downsampled:\n",
        "  sent = \"<START> \" + line + \" <END>\"\n",
        "  modified_target_text_downsampled.append(sent)"
      ],
      "metadata": {
        "id": "2Qfyi9QroG5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_target_text_downsampled[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j20iCENEqNNw",
        "outputId": "90020ab6-6ff9-4fa1-dcb1-f92253a4ce97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START> ngoh .  <END>',\n",
              " '<START> pamphlet . pamphlet . here you go , kids ,  take a pamphlet .  <END>',\n",
              " '<START> do not worry , mr . twig . even though mr . hat rescued me from prison , i am still going to stick with you . <END>',\n",
              " '<START> congratulations , bridon . guess we will be working a lot together . <END>']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "target_tokenizer.fit_on_texts(target_text_downsampled)\n",
        "tokenized_target_text = target_tokenizer.texts_to_sequences(target_text_downsampled)"
      ],
      "metadata": {
        "id": "viHhvflvqNRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_target_text_downsampled = 0\n",
        "\n",
        "for sentence in tokenized_target_text:\n",
        "  if len(sentence) >= max_len_target_text_downsampled:\n",
        "    max_len_target_text_downsampled = len(sentence)"
      ],
      "metadata": {
        "id": "mg8s4sQeqNUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_target_text_downsampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln051uOuqNX6",
        "outputId": "0e8c224b-440c-4608-e0dd-dff1f99e4fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_target_text_downsampled = keras.preprocessing.sequence.pad_sequences(tokenized_target_text, \n",
        "                                  maxlen=max_len_target_text_downsampled, padding=\"post\")\n",
        "decoder_input_data_ds = np.array(padded_target_text_downsampled)"
      ],
      "metadata": {
        "id": "sZAUAyULqNbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-aHSAAMoG14",
        "outputId": "59666dc3-d8ef-4a6a-e95c-e7e7b96c2f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAGfJoMOYnyi",
        "outputId": "0d0f9a64-72e3-41a5-ec03-906fae40823c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2449,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_text_downsampled_vocab_dict = target_tokenizer.word_index \n",
        "num_decoder_tokens = len(target_text_downsampled_vocab_dict) + 1"
      ],
      "metadata": {
        "id": "dyJEDWgdsaA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XC017oQsZ8P",
        "outputId": "097baf4c-fb78-4ae3-ffc0-55df86665d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5775"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Preparing target data for decoder `(decoder_output_data)`\n",
        "\n",
        "1. Remove only the `<START>` tag from each sentence \n",
        "2. Convert the modified `padded_target_text` to one hot vectors"
      ],
      "metadata": {
        "id": "J__d__8yvfsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_target_data = []\n",
        "\n",
        "for sentence in tokenized_target_text:\n",
        "  decoder_output_target_data.append(sentence[1:])"
      ],
      "metadata": {
        "id": "xO_OMqG_vfT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_decoder_output_data = keras.preprocessing.sequence.pad_sequences(decoder_output_target_data,\n",
        "                              maxlen=max_len_target_text_downsampled, padding=\"post\")\n",
        "\n",
        "one_hot_encoding_target_data = tf.keras.utils.to_categorical(padded_decoder_output_data, num_decoder_tokens)\n",
        "decoder_output_data_ds = np.array(one_hot_encoding_target_data)"
      ],
      "metadata": {
        "id": "_7MPf546ve_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output_data_ds[0]"
      ],
      "metadata": {
        "id": "3jHncFiesZ4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110d0e51-2114-4c3a-b14d-fdb2cee81c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "30rpUTIKlnFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Using the traditional way to create vocab dict and inverse vocab dict"
      ],
      "metadata": {
        "id": "mgyON8cJjfJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modified_target_text_downsampled = []\n",
        "\n",
        "for sentence in target_text_downsampled:\n",
        "  sent = \"<SOS> \" + sentence + \" <EOS>\"\n",
        "  modified_target_text_downsampled.append(sent)"
      ],
      "metadata": {
        "id": "3G8mtNCLzbzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SSd0CluNsxqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vocab_threshold_downsampled = {}\n",
        "target_vocab_threshold_downsampled = {}\n",
        "\n",
        "for sentence in source_text_downsampled:\n",
        "  for word in sentence.split():\n",
        "    if word not in source_vocab_threshold_downsampled:\n",
        "      source_vocab_threshold_downsampled[word] = 1\n",
        "    else:\n",
        "      source_vocab_threshold_downsampled[word] += 1\n",
        "\n",
        "for sentence in modified_target_text_downsampled:\n",
        "  for word in sentence.split():\n",
        "    if word not in target_vocab_threshold_downsampled:\n",
        "      target_vocab_threshold_downsampled[word] = 1\n",
        "    else:\n",
        "      target_vocab_threshold_downsampled[word] += 1"
      ],
      "metadata": {
        "id": "dL0ofNm5uz5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_vocab_threshold_downsampled), len(target_vocab_threshold_downsampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxVBqe0FvZcc",
        "outputId": "8bfa2fe0-799e-469a-d753-63b6b21ef9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7714, 7662)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2\n",
        "\n",
        "source_vocab_to_int_downsampled = {}\n",
        "target_vocab_to_int_downsampled = {}\n",
        "\n",
        "count_source = 0\n",
        "for key, values in source_vocab_threshold_downsampled.items():\n",
        "  if values>=threshold:\n",
        "    source_vocab_to_int_downsampled[key] = count_source\n",
        "    count_source += 1\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "count_target = 0\n",
        "for key, values in target_vocab_threshold_downsampled.items():\n",
        "  if values>=threshold:\n",
        "    target_vocab_to_int_downsampled[key] = count_target\n",
        "    count_target += 1\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "PKJnsAJ8tbj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
        "\n",
        "for token in tokens:\n",
        "  source_vocab_to_int_downsampled[token] = len(source_vocab_to_int_downsampled)+1\n",
        "\n",
        "for token in tokens:\n",
        "  if token not in target_vocab_to_int_downsampled:\n",
        "    target_vocab_to_int_downsampled[token] = len(target_vocab_to_int_downsampled)+1"
      ],
      "metadata": {
        "id": "AnpDTl4M0fB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(source_vocab_to_int_downsampled), len(target_vocab_to_int_downsampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVB1AgqDtboM",
        "outputId": "273b1427-e189-4bba-eabc-37b1ef46dc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 2437)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inv_source_vocab_downsampled = {y:x for x,y in source_vocab_to_int_downsampled.items()}\n",
        "inv_target_vocab_downsampled = {y:x for x,y in target_vocab_to_int_downsampled.items()}"
      ],
      "metadata": {
        "id": "HXTivW7rtbrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_source_downsampled = 0\n",
        "max_len_target_downsampled = 0\n",
        "\n",
        "for sentence in source_text_downsampled:\n",
        "  length = len(sentence.split())\n",
        "  if length >= max_len_source_downsampled:\n",
        "    max_len_source_downsampled = length\n",
        "\n",
        "for sentence in target_text_downsampled:\n",
        "  length = len(sentence.split())\n",
        "  if length >= max_len_target_downsampled:\n",
        "    max_len_target_downsampled = length"
      ],
      "metadata": {
        "id": "NMwD47xqsyfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_source_downsampled, max_len_target_downsampled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpkzOeWuum9c",
        "outputId": "5da01fe2-ba5a-4637-8625-1238af85969f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 42)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Using numpy arrays to create a sparse matrix for encoder and decoder input-output data"
      ],
      "metadata": {
        "id": "-iM2RGhXunBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data_downsampled = np.zeros((len(source_text_downsampled), max_len_source_downsampled, len(source_vocab_to_int_downsampled)), \n",
        "                                          dtype=\"float32\")\n",
        "\n",
        "decoder_input_data_downsampled = np.zeros((len(target_text_downsampled), max_len_target_downsampled, len(target_vocab_to_int_downsampled)),\n",
        "                                          dtype=\"float32\")\n",
        "\n",
        "decoder_output_data_downsampled = np.zeros((len(target_text_downsampled), max_len_target_downsampled, len(target_vocab_to_int_downsampled)),\n",
        "                                          dtype=\"float32\")"
      ],
      "metadata": {
        "id": "WqUX_0O2unEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line, (input_line, target_line) in enumerate(zip(source_text_downsampled, target_text_downsampled)):\n",
        "\n",
        "  for timestep, token in enumerate(input_line.split()):\n",
        "\n",
        "    if token in source_vocab_to_int_downsampled:\n",
        "      encoder_input_data_downsampled[line, timestep, source_vocab_to_int_downsampled[token]] = 1\n",
        "    else:\n",
        "      encoder_input_data_downsampled[line, timestep, source_vocab_to_int_downsampled[\"<UNK>\"]-1] = 1\n",
        "\n",
        "  for timestep, token in enumerate(target_line.split()):\n",
        "\n",
        "    if token in target_vocab_to_int_downsampled:\n",
        "      decoder_input_data_downsampled[line, timestep, target_vocab_to_int_downsampled[token]] = 1\n",
        "      if timestep>0:\n",
        "        decoder_output_data_downsampled[line, timestep-1, target_vocab_to_int_downsampled[token]] = 1\n",
        "    else:\n",
        "      decoder_input_data_downsampled[line, timestep, target_vocab_to_int_downsampled[\"<UNK>\"]-1] = 1\n",
        "      if timestep>0:\n",
        "        decoder_output_data_downsampled[line, timestep, target_vocab_to_int_downsampled[\"<UNK>\"]-1] = 1"
      ],
      "metadata": {
        "id": "l6XYXoJDunLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XsSt7CIZgMAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Encoder-Decoder model"
      ],
      "metadata": {
        "id": "YdlsCAlI2YKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.layers.Input(shape=(None, ))\n",
        "encoder_emb = keras.layers.Embedding(num_encoder_tokens, 256, mask_zero=True)(encoder_inputs)\n",
        "encoder_lstm = keras.layers.LSTM(256, return_state=True)\n",
        "encoder_outputs, hidden_state, cell_state = encoder_lstm(encoder_emb)\n",
        "encoder_states = [hidden_state, cell_state]\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=(None, ))\n",
        "decoder_emb = keras.layers.Embedding(num_decoder_tokens, 256, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = keras.layers.LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_emb, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
        "\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"],\n",
        "              optimizer=keras.optimizers.RMSprop())"
      ],
      "metadata": {
        "id": "utHC74kx3IYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "1UBVkNZw6tNZ",
        "outputId": "c741b101-107b-47b4-d8cf-d231c4484983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([encoder_input_data_ds, decoder_input_data_ds], decoder_output_data_ds,\n",
        "                    batch_size=64, epochs=200, validation_split=0.15)"
      ],
      "metadata": {
        "id": "G60uY1JM33kE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a28e5d-a11a-4717-b645-a7c989444172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "67/67 [==============================] - 19s 124ms/step - loss: 1.6448 - accuracy: 0.1004 - val_loss: 1.5366 - val_accuracy: 0.1040\n",
            "Epoch 2/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.5291 - accuracy: 0.1020 - val_loss: 1.5354 - val_accuracy: 0.1067\n",
            "Epoch 3/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 1.4914 - accuracy: 0.1096 - val_loss: 1.5115 - val_accuracy: 0.1162\n",
            "Epoch 4/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.4480 - accuracy: 0.1289 - val_loss: 1.4816 - val_accuracy: 0.1384\n",
            "Epoch 5/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.4059 - accuracy: 0.1438 - val_loss: 1.4602 - val_accuracy: 0.1505\n",
            "Epoch 6/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 1.3703 - accuracy: 0.1549 - val_loss: 1.4485 - val_accuracy: 0.1566\n",
            "Epoch 7/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.3393 - accuracy: 0.1638 - val_loss: 1.4383 - val_accuracy: 0.1612\n",
            "Epoch 8/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.3108 - accuracy: 0.1713 - val_loss: 1.4320 - val_accuracy: 0.1659\n",
            "Epoch 9/200\n",
            "67/67 [==============================] - 5s 77ms/step - loss: 1.2839 - accuracy: 0.1772 - val_loss: 1.4288 - val_accuracy: 0.1685\n",
            "Epoch 10/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 1.2578 - accuracy: 0.1846 - val_loss: 1.4285 - val_accuracy: 0.1730\n",
            "Epoch 11/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.2328 - accuracy: 0.1910 - val_loss: 1.4251 - val_accuracy: 0.1773\n",
            "Epoch 12/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.2088 - accuracy: 0.1969 - val_loss: 1.4314 - val_accuracy: 0.1764\n",
            "Epoch 13/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 1.1852 - accuracy: 0.2018 - val_loss: 1.4367 - val_accuracy: 0.1796\n",
            "Epoch 14/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.1622 - accuracy: 0.2081 - val_loss: 1.4393 - val_accuracy: 0.1780\n",
            "Epoch 15/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.1390 - accuracy: 0.2132 - val_loss: 1.4403 - val_accuracy: 0.1794\n",
            "Epoch 16/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.1176 - accuracy: 0.2194 - val_loss: 1.4476 - val_accuracy: 0.1778\n",
            "Epoch 17/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.0946 - accuracy: 0.2250 - val_loss: 1.4534 - val_accuracy: 0.1780\n",
            "Epoch 18/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.0722 - accuracy: 0.2326 - val_loss: 1.4630 - val_accuracy: 0.1736\n",
            "Epoch 19/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.0507 - accuracy: 0.2370 - val_loss: 1.4679 - val_accuracy: 0.1747\n",
            "Epoch 20/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 1.0284 - accuracy: 0.2445 - val_loss: 1.4768 - val_accuracy: 0.1683\n",
            "Epoch 21/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 1.0059 - accuracy: 0.2536 - val_loss: 1.4854 - val_accuracy: 0.1693\n",
            "Epoch 22/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.9843 - accuracy: 0.2601 - val_loss: 1.4904 - val_accuracy: 0.1689\n",
            "Epoch 23/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.9611 - accuracy: 0.2705 - val_loss: 1.5030 - val_accuracy: 0.1673\n",
            "Epoch 24/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.9391 - accuracy: 0.2783 - val_loss: 1.5085 - val_accuracy: 0.1597\n",
            "Epoch 25/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.9160 - accuracy: 0.2883 - val_loss: 1.5225 - val_accuracy: 0.1698\n",
            "Epoch 26/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.8937 - accuracy: 0.3000 - val_loss: 1.5298 - val_accuracy: 0.1651\n",
            "Epoch 27/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.8703 - accuracy: 0.3120 - val_loss: 1.5377 - val_accuracy: 0.1591\n",
            "Epoch 28/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.8483 - accuracy: 0.3243 - val_loss: 1.5420 - val_accuracy: 0.1559\n",
            "Epoch 29/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.8265 - accuracy: 0.3370 - val_loss: 1.5577 - val_accuracy: 0.1573\n",
            "Epoch 30/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.8037 - accuracy: 0.3490 - val_loss: 1.5653 - val_accuracy: 0.1583\n",
            "Epoch 31/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.7813 - accuracy: 0.3640 - val_loss: 1.5838 - val_accuracy: 0.1477\n",
            "Epoch 32/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.7579 - accuracy: 0.3819 - val_loss: 1.5997 - val_accuracy: 0.1473\n",
            "Epoch 33/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.7358 - accuracy: 0.3951 - val_loss: 1.6119 - val_accuracy: 0.1521\n",
            "Epoch 34/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.7136 - accuracy: 0.4146 - val_loss: 1.6207 - val_accuracy: 0.1470\n",
            "Epoch 35/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.6909 - accuracy: 0.4322 - val_loss: 1.6320 - val_accuracy: 0.1490\n",
            "Epoch 36/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.6685 - accuracy: 0.4506 - val_loss: 1.6423 - val_accuracy: 0.1447\n",
            "Epoch 37/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.6464 - accuracy: 0.4683 - val_loss: 1.6493 - val_accuracy: 0.1384\n",
            "Epoch 38/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.6246 - accuracy: 0.4859 - val_loss: 1.6695 - val_accuracy: 0.1415\n",
            "Epoch 39/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.6031 - accuracy: 0.5066 - val_loss: 1.6839 - val_accuracy: 0.1419\n",
            "Epoch 40/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.5827 - accuracy: 0.5244 - val_loss: 1.6957 - val_accuracy: 0.1420\n",
            "Epoch 41/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.5609 - accuracy: 0.5427 - val_loss: 1.7107 - val_accuracy: 0.1386\n",
            "Epoch 42/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.5411 - accuracy: 0.5600 - val_loss: 1.7243 - val_accuracy: 0.1394\n",
            "Epoch 43/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.5204 - accuracy: 0.5797 - val_loss: 1.7392 - val_accuracy: 0.1365\n",
            "Epoch 44/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.5004 - accuracy: 0.5976 - val_loss: 1.7553 - val_accuracy: 0.1359\n",
            "Epoch 45/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.4805 - accuracy: 0.6176 - val_loss: 1.7648 - val_accuracy: 0.1379\n",
            "Epoch 46/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.4623 - accuracy: 0.6323 - val_loss: 1.7725 - val_accuracy: 0.1305\n",
            "Epoch 47/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.4436 - accuracy: 0.6505 - val_loss: 1.7833 - val_accuracy: 0.1290\n",
            "Epoch 48/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.4242 - accuracy: 0.6686 - val_loss: 1.8055 - val_accuracy: 0.1345\n",
            "Epoch 49/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.4074 - accuracy: 0.6832 - val_loss: 1.8253 - val_accuracy: 0.1333\n",
            "Epoch 50/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.3891 - accuracy: 0.7002 - val_loss: 1.8340 - val_accuracy: 0.1319\n",
            "Epoch 51/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.3722 - accuracy: 0.7153 - val_loss: 1.8452 - val_accuracy: 0.1281\n",
            "Epoch 52/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.3554 - accuracy: 0.7333 - val_loss: 1.8656 - val_accuracy: 0.1295\n",
            "Epoch 53/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.3391 - accuracy: 0.7480 - val_loss: 1.8782 - val_accuracy: 0.1241\n",
            "Epoch 54/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.3230 - accuracy: 0.7621 - val_loss: 1.8966 - val_accuracy: 0.1240\n",
            "Epoch 55/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.3084 - accuracy: 0.7764 - val_loss: 1.9096 - val_accuracy: 0.1268\n",
            "Epoch 56/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2933 - accuracy: 0.7901 - val_loss: 1.9313 - val_accuracy: 0.1233\n",
            "Epoch 57/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2789 - accuracy: 0.8035 - val_loss: 1.9346 - val_accuracy: 0.1229\n",
            "Epoch 58/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2650 - accuracy: 0.8147 - val_loss: 1.9625 - val_accuracy: 0.1236\n",
            "Epoch 59/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.2519 - accuracy: 0.8263 - val_loss: 1.9659 - val_accuracy: 0.1181\n",
            "Epoch 60/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2394 - accuracy: 0.8397 - val_loss: 1.9892 - val_accuracy: 0.1172\n",
            "Epoch 61/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.2254 - accuracy: 0.8524 - val_loss: 2.0035 - val_accuracy: 0.1177\n",
            "Epoch 62/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2136 - accuracy: 0.8609 - val_loss: 2.0194 - val_accuracy: 0.1190\n",
            "Epoch 63/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.2025 - accuracy: 0.8715 - val_loss: 2.0336 - val_accuracy: 0.1110\n",
            "Epoch 64/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1916 - accuracy: 0.8806 - val_loss: 2.0499 - val_accuracy: 0.1176\n",
            "Epoch 65/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1801 - accuracy: 0.8924 - val_loss: 2.0624 - val_accuracy: 0.1119\n",
            "Epoch 66/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1701 - accuracy: 0.9002 - val_loss: 2.0685 - val_accuracy: 0.1124\n",
            "Epoch 67/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1602 - accuracy: 0.9086 - val_loss: 2.0912 - val_accuracy: 0.1119\n",
            "Epoch 68/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.1504 - accuracy: 0.9176 - val_loss: 2.1129 - val_accuracy: 0.1140\n",
            "Epoch 69/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.1414 - accuracy: 0.9241 - val_loss: 2.1199 - val_accuracy: 0.1127\n",
            "Epoch 70/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1328 - accuracy: 0.9303 - val_loss: 2.1355 - val_accuracy: 0.1108\n",
            "Epoch 71/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.1240 - accuracy: 0.9389 - val_loss: 2.1629 - val_accuracy: 0.1105\n",
            "Epoch 72/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.1157 - accuracy: 0.9454 - val_loss: 2.1670 - val_accuracy: 0.1124\n",
            "Epoch 73/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.1094 - accuracy: 0.9490 - val_loss: 2.1822 - val_accuracy: 0.1105\n",
            "Epoch 74/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.1012 - accuracy: 0.9552 - val_loss: 2.1950 - val_accuracy: 0.1095\n",
            "Epoch 75/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0954 - accuracy: 0.9584 - val_loss: 2.2160 - val_accuracy: 0.1117\n",
            "Epoch 76/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0882 - accuracy: 0.9649 - val_loss: 2.2280 - val_accuracy: 0.1109\n",
            "Epoch 77/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0818 - accuracy: 0.9684 - val_loss: 2.2395 - val_accuracy: 0.1076\n",
            "Epoch 78/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0763 - accuracy: 0.9728 - val_loss: 2.2625 - val_accuracy: 0.1088\n",
            "Epoch 79/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0709 - accuracy: 0.9767 - val_loss: 2.2656 - val_accuracy: 0.1066\n",
            "Epoch 80/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0660 - accuracy: 0.9790 - val_loss: 2.2829 - val_accuracy: 0.1077\n",
            "Epoch 81/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 2.3037 - val_accuracy: 0.1101\n",
            "Epoch 82/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0567 - accuracy: 0.9838 - val_loss: 2.3079 - val_accuracy: 0.1099\n",
            "Epoch 83/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0520 - accuracy: 0.9863 - val_loss: 2.3253 - val_accuracy: 0.1081\n",
            "Epoch 84/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 2.3437 - val_accuracy: 0.1063\n",
            "Epoch 85/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0448 - accuracy: 0.9892 - val_loss: 2.3583 - val_accuracy: 0.1069\n",
            "Epoch 86/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0411 - accuracy: 0.9911 - val_loss: 2.3696 - val_accuracy: 0.1098\n",
            "Epoch 87/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0380 - accuracy: 0.9919 - val_loss: 2.3824 - val_accuracy: 0.1060\n",
            "Epoch 88/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0351 - accuracy: 0.9928 - val_loss: 2.3985 - val_accuracy: 0.1088\n",
            "Epoch 89/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0323 - accuracy: 0.9939 - val_loss: 2.4092 - val_accuracy: 0.1067\n",
            "Epoch 90/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0298 - accuracy: 0.9947 - val_loss: 2.4150 - val_accuracy: 0.1070\n",
            "Epoch 91/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0271 - accuracy: 0.9956 - val_loss: 2.4339 - val_accuracy: 0.1059\n",
            "Epoch 92/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 2.4549 - val_accuracy: 0.1060\n",
            "Epoch 93/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0232 - accuracy: 0.9965 - val_loss: 2.4605 - val_accuracy: 0.1022\n",
            "Epoch 94/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 2.4746 - val_accuracy: 0.1035\n",
            "Epoch 95/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 2.4906 - val_accuracy: 0.1069\n",
            "Epoch 96/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0184 - accuracy: 0.9972 - val_loss: 2.4975 - val_accuracy: 0.1054\n",
            "Epoch 97/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0167 - accuracy: 0.9976 - val_loss: 2.5084 - val_accuracy: 0.1062\n",
            "Epoch 98/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0157 - accuracy: 0.9976 - val_loss: 2.5163 - val_accuracy: 0.1067\n",
            "Epoch 99/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 2.5411 - val_accuracy: 0.1066\n",
            "Epoch 100/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0131 - accuracy: 0.9978 - val_loss: 2.5487 - val_accuracy: 0.1062\n",
            "Epoch 101/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 2.5530 - val_accuracy: 0.1065\n",
            "Epoch 102/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 2.5678 - val_accuracy: 0.1065\n",
            "Epoch 103/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 2.5836 - val_accuracy: 0.1059\n",
            "Epoch 104/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 2.5957 - val_accuracy: 0.1035\n",
            "Epoch 105/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 2.6054 - val_accuracy: 0.1092\n",
            "Epoch 106/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 2.6136 - val_accuracy: 0.1031\n",
            "Epoch 107/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 2.6152 - val_accuracy: 0.1037\n",
            "Epoch 108/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 2.6340 - val_accuracy: 0.1056\n",
            "Epoch 109/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 2.6478 - val_accuracy: 0.1067\n",
            "Epoch 110/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 2.6609 - val_accuracy: 0.1098\n",
            "Epoch 111/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 2.6749 - val_accuracy: 0.1063\n",
            "Epoch 112/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 2.6798 - val_accuracy: 0.1060\n",
            "Epoch 113/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 2.6813 - val_accuracy: 0.1038\n",
            "Epoch 114/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 2.6907 - val_accuracy: 0.1091\n",
            "Epoch 115/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 2.6968 - val_accuracy: 0.1024\n",
            "Epoch 116/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 2.7075 - val_accuracy: 0.1062\n",
            "Epoch 117/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 2.7178 - val_accuracy: 0.1065\n",
            "Epoch 118/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 2.7339 - val_accuracy: 0.1066\n",
            "Epoch 119/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 2.7332 - val_accuracy: 0.1084\n",
            "Epoch 120/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0038 - accuracy: 0.9982 - val_loss: 2.7424 - val_accuracy: 0.1073\n",
            "Epoch 121/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 2.7465 - val_accuracy: 0.1052\n",
            "Epoch 122/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 2.7654 - val_accuracy: 0.1060\n",
            "Epoch 123/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 2.7733 - val_accuracy: 0.1062\n",
            "Epoch 124/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 2.7868 - val_accuracy: 0.1063\n",
            "Epoch 125/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 2.7918 - val_accuracy: 0.1052\n",
            "Epoch 126/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 2.8062 - val_accuracy: 0.1079\n",
            "Epoch 127/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 2.8028 - val_accuracy: 0.1052\n",
            "Epoch 128/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 2.8174 - val_accuracy: 0.1059\n",
            "Epoch 129/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0024 - accuracy: 0.9984 - val_loss: 2.8278 - val_accuracy: 0.1073\n",
            "Epoch 130/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0023 - accuracy: 0.9986 - val_loss: 2.8387 - val_accuracy: 0.1054\n",
            "Epoch 131/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0028 - accuracy: 0.9981 - val_loss: 2.8306 - val_accuracy: 0.1028\n",
            "Epoch 132/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 2.8396 - val_accuracy: 0.1045\n",
            "Epoch 133/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0023 - accuracy: 0.9983 - val_loss: 2.8470 - val_accuracy: 0.1051\n",
            "Epoch 134/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0026 - accuracy: 0.9980 - val_loss: 2.8563 - val_accuracy: 0.1054\n",
            "Epoch 135/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0023 - accuracy: 0.9982 - val_loss: 2.8710 - val_accuracy: 0.1085\n",
            "Epoch 136/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0022 - accuracy: 0.9982 - val_loss: 2.8673 - val_accuracy: 0.1084\n",
            "Epoch 137/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0023 - accuracy: 0.9981 - val_loss: 2.8723 - val_accuracy: 0.1051\n",
            "Epoch 138/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0022 - accuracy: 0.9983 - val_loss: 2.8849 - val_accuracy: 0.1058\n",
            "Epoch 139/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 2.8823 - val_accuracy: 0.1056\n",
            "Epoch 140/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0024 - accuracy: 0.9981 - val_loss: 2.8833 - val_accuracy: 0.1024\n",
            "Epoch 141/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0022 - accuracy: 0.9981 - val_loss: 2.8969 - val_accuracy: 0.1066\n",
            "Epoch 142/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0021 - accuracy: 0.9983 - val_loss: 2.8947 - val_accuracy: 0.1059\n",
            "Epoch 143/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0018 - accuracy: 0.9983 - val_loss: 2.9091 - val_accuracy: 0.1051\n",
            "Epoch 144/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0017 - accuracy: 0.9982 - val_loss: 2.9146 - val_accuracy: 0.1031\n",
            "Epoch 145/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 2.9306 - val_accuracy: 0.1038\n",
            "Epoch 146/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0020 - accuracy: 0.9982 - val_loss: 2.9305 - val_accuracy: 0.1060\n",
            "Epoch 147/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0016 - accuracy: 0.9986 - val_loss: 2.9423 - val_accuracy: 0.1063\n",
            "Epoch 148/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 2.9488 - val_accuracy: 0.1044\n",
            "Epoch 149/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 2.9576 - val_accuracy: 0.1045\n",
            "Epoch 150/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0017 - accuracy: 0.9984 - val_loss: 2.9530 - val_accuracy: 0.1070\n",
            "Epoch 151/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0015 - accuracy: 0.9986 - val_loss: 2.9616 - val_accuracy: 0.1065\n",
            "Epoch 152/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0015 - accuracy: 0.9985 - val_loss: 2.9716 - val_accuracy: 0.1077\n",
            "Epoch 153/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0016 - accuracy: 0.9983 - val_loss: 2.9806 - val_accuracy: 0.1023\n",
            "Epoch 154/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0024 - accuracy: 0.9976 - val_loss: 2.9805 - val_accuracy: 0.1041\n",
            "Epoch 155/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0016 - accuracy: 0.9982 - val_loss: 2.9857 - val_accuracy: 0.1042\n",
            "Epoch 156/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 3.0021 - val_accuracy: 0.1034\n",
            "Epoch 157/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 3.0092 - val_accuracy: 0.1012\n",
            "Epoch 158/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 3.0051 - val_accuracy: 0.1060\n",
            "Epoch 159/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0015 - accuracy: 0.9986 - val_loss: 3.0120 - val_accuracy: 0.1031\n",
            "Epoch 160/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 3.0214 - val_accuracy: 0.1045\n",
            "Epoch 161/200\n",
            "67/67 [==============================] - 5s 73ms/step - loss: 0.0014 - accuracy: 0.9983 - val_loss: 3.0077 - val_accuracy: 0.1059\n",
            "Epoch 162/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0015 - accuracy: 0.9983 - val_loss: 3.0249 - val_accuracy: 0.1035\n",
            "Epoch 163/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9983 - val_loss: 3.0417 - val_accuracy: 0.1016\n",
            "Epoch 164/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0020 - accuracy: 0.9978 - val_loss: 3.0303 - val_accuracy: 0.1045\n",
            "Epoch 165/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 3.0374 - val_accuracy: 0.1045\n",
            "Epoch 166/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 3.0430 - val_accuracy: 0.1045\n",
            "Epoch 167/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9984 - val_loss: 3.0406 - val_accuracy: 0.1013\n",
            "Epoch 168/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0014 - accuracy: 0.9984 - val_loss: 3.0448 - val_accuracy: 0.1045\n",
            "Epoch 169/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9984 - val_loss: 3.0531 - val_accuracy: 0.1037\n",
            "Epoch 170/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 3.0702 - val_accuracy: 0.1038\n",
            "Epoch 171/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0013 - accuracy: 0.9984 - val_loss: 3.0752 - val_accuracy: 0.1026\n",
            "Epoch 172/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0013 - accuracy: 0.9983 - val_loss: 3.0711 - val_accuracy: 0.1030\n",
            "Epoch 173/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 3.0931 - val_accuracy: 0.1069\n",
            "Epoch 174/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0013 - accuracy: 0.9983 - val_loss: 3.0864 - val_accuracy: 0.1047\n",
            "Epoch 175/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0012 - accuracy: 0.9985 - val_loss: 3.0992 - val_accuracy: 0.1045\n",
            "Epoch 176/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 3.0936 - val_accuracy: 0.1048\n",
            "Epoch 177/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0012 - accuracy: 0.9986 - val_loss: 3.1046 - val_accuracy: 0.1066\n",
            "Epoch 178/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0014 - accuracy: 0.9983 - val_loss: 3.0880 - val_accuracy: 0.1035\n",
            "Epoch 179/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 3.1056 - val_accuracy: 0.1023\n",
            "Epoch 180/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0013 - accuracy: 0.9982 - val_loss: 3.1082 - val_accuracy: 0.1059\n",
            "Epoch 181/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 3.1121 - val_accuracy: 0.1044\n",
            "Epoch 182/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0012 - accuracy: 0.9985 - val_loss: 3.1238 - val_accuracy: 0.1006\n",
            "Epoch 183/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0013 - accuracy: 0.9983 - val_loss: 3.1129 - val_accuracy: 0.1054\n",
            "Epoch 184/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0012 - accuracy: 0.9984 - val_loss: 3.1219 - val_accuracy: 0.1044\n",
            "Epoch 185/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0012 - accuracy: 0.9983 - val_loss: 3.1371 - val_accuracy: 0.1058\n",
            "Epoch 186/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0011 - accuracy: 0.9987 - val_loss: 3.1429 - val_accuracy: 0.1062\n",
            "Epoch 187/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0011 - accuracy: 0.9986 - val_loss: 3.1504 - val_accuracy: 0.1026\n",
            "Epoch 188/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 3.1415 - val_accuracy: 0.1059\n",
            "Epoch 189/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 9.9948e-04 - accuracy: 0.9986 - val_loss: 3.1620 - val_accuracy: 0.1069\n",
            "Epoch 190/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0011 - accuracy: 0.9987 - val_loss: 3.1629 - val_accuracy: 0.1067\n",
            "Epoch 191/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0011 - accuracy: 0.9984 - val_loss: 3.1671 - val_accuracy: 0.1055\n",
            "Epoch 192/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 0.0010 - accuracy: 0.9985 - val_loss: 3.1768 - val_accuracy: 0.1052\n",
            "Epoch 193/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 3.1751 - val_accuracy: 0.1048\n",
            "Epoch 194/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 3.1833 - val_accuracy: 0.1030\n",
            "Epoch 195/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0010 - accuracy: 0.9983 - val_loss: 3.1827 - val_accuracy: 0.1072\n",
            "Epoch 196/200\n",
            "67/67 [==============================] - 5s 76ms/step - loss: 9.6610e-04 - accuracy: 0.9986 - val_loss: 3.2026 - val_accuracy: 0.1023\n",
            "Epoch 197/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 0.0011 - accuracy: 0.9985 - val_loss: 3.1957 - val_accuracy: 0.1034\n",
            "Epoch 198/200\n",
            "67/67 [==============================] - 5s 74ms/step - loss: 0.0015 - accuracy: 0.9981 - val_loss: 3.1968 - val_accuracy: 0.1017\n",
            "Epoch 199/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 9.5169e-04 - accuracy: 0.9985 - val_loss: 3.2078 - val_accuracy: 0.1083\n",
            "Epoch 200/200\n",
            "67/67 [==============================] - 5s 75ms/step - loss: 9.7752e-04 - accuracy: 0.9985 - val_loss: 3.2114 - val_accuracy: 0.1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1nuWZu6R33nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference mode "
      ],
      "metadata": {
        "id": "CVB7woYTTXNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference_models():\n",
        "\n",
        "  encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "  decoder_hidden_state_input = keras.layers.Input(shape=(256, ))\n",
        "  decoder_cell_state_output = keras.layers.Input(shape=(256, ))\n",
        "\n",
        "  decoder_input_states = [decoder_hidden_state_input, decoder_cell_state_output]\n",
        "\n",
        "  decoder_outputs, state_h, state_c = decoder_lstm(decoder_emb, initial_state=decoder_input_states)\n",
        "  decoder_states = [state_h, state_c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = keras.Model([decoder_inputs] + decoder_input_states,\n",
        "                              [decoder_outputs] + decoder_states)\n",
        "\n",
        "  return encoder_model, decoder_model"
      ],
      "metadata": {
        "id": "jCBgeMq_33q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_tokens(sentence:str):\n",
        "\n",
        "  words = clean_text(sentence).split()\n",
        "  tokens_list = []\n",
        "\n",
        "  for word in words:\n",
        "    tokens_list.append(source_text_downsampled_vocab_dict[word])\n",
        "\n",
        "  return keras.preprocessing.sequence.pad_sequences([tokens_list], \n",
        "                                                    maxlen=max_length_source_text_downsampled, padding=\"post\")"
      ],
      "metadata": {
        "id": "eHePbQTo33uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model, dec_model = make_inference_models()\n",
        "\n",
        "for epoch in range(encoder_input_data_ds.shape[0]):\n",
        "  states_values = enc_model.predict(str_to_tokens(input()))\n",
        "  empty_target_seq = np.zeros((1,1))\n",
        "  empty_target_seq[0,0] = target_text_downsampled_vocab_dict[\"start\"]\n",
        "  stop_condition = False\n",
        "\n",
        "  decoded_translation = \"\"\n",
        "  while not stop_condition:\n",
        "    dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
        "    sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "    sampled_word = None\n",
        "\n",
        "    for word, index in target_text_downsampled_vocab_dict.items():\n",
        "      if sampled_word_index == index:\n",
        "        decoded_translation += \" {}\".format(word)\n",
        "        sampled_word = word\n",
        "    \n",
        "    if sampled_word == \"end\" or len(decoded_translation.split())>max_len_target_text_downsampled:\n",
        "      stop_condition = True\n",
        "\n",
        "    empty_target_seq = np.zeros((1,1))\n",
        "    empty_target_seq[0,0] = sampled_word_index\n",
        "    states_values = [h,c]\n",
        "\n",
        "  print(decoded_translation)"
      ],
      "metadata": {
        "id": "Ve08QHcq33x5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "39ca4045-ab33-407a-f4b3-4575b38f84da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            " corey lanskin broke the broke the okay anymore no terrance broke broke me broke broke me broke broke the wrong looking at the school she will be on the school spread the world as why she has the beatles\n",
            "okay\n",
            " there is a better than i need to mean to stop you broke me your way broke broke the broke the broke broke the future broke broke the future alive broke broke the future broke broke the future broke\n",
            "fuck \n",
            " do not think about this i have to kill him broke broke our arms again girl want to broke the broke here broke the future broke broke the boy broke the boy as fuck us broke broke the broke\n",
            "hi\n",
            " broke the me broke the me broke me so you try but just like such a school broke broke the future broke broke broke broke a me pick with me before you and as santa other on us we\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-1c7d6efa0d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_data_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_text_downsampled_vocab_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MAhKTZE6lDH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}