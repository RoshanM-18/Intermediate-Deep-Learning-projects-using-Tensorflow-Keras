{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow research",
      "provenance": [],
      "authorship_tag": "ABX9TyMrXG/OV1iCyIvGFWKa+Mzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanM-18/Intermediate-Deep-Learning-projects-using-Tensorflow-Keras/blob/main/Tensorflow_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "d4af_iApSo7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "nElo1ncvhZlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "ePBmS7SpZva5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tf gradient\n",
        "\n",
        "1. tf gradient tape can be used to make your own custom optimizer and that is used for automatic differentiation\n",
        "3. now if you wanna keep the value of x in the next gradient tape as well you have to use persistent = True. To compute multiple gradients over the same coomputation we have to create a persistent gradient tape . this allows multiple calls to the gradient function"
      ],
      "metadata": {
        "id": "ynKIyQ-owe65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Automatic differentiation\n",
        "\n",
        "There are four types of differentiation\n",
        "1. manual -> the one we used to do in college\n",
        "2. numeric -> didnt understand\n",
        "3. symbolic -> automated version of manual differentiation\n",
        "4. automatic -> abstractions that enable you to write a function and efficiently apply the chain rule to it\n",
        "\n",
        "automatic differentiation (autodiff) refers to a general way of taking a program which computes a value and automatically constructing a procedure for computing derivatives of that value. \n",
        "\n",
        "There are two versions of automatic differentiation\n",
        "1. forward mode              2. reverse mode\n"
      ],
      "metadata": {
        "id": "0OWqG-aorKPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQJnlztO1dKA",
        "outputId": "e903d794-2f06-4d8f-b6e3-1c15866d7dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eager execution\n",
        "\n",
        "1. in PyTorch, `eager execution` is termed as \"dynamic computation graphs\" (default execution method) and `graph execution` is termed as \"static computation graphs\"\n",
        "2. It does not build graphs, and the operations return actual values instead of computational graphs to run later. With Eager execution, TensorFlow calculates the values of tensors as they occur in your code.\n",
        "\n",
        "``` Eager execution is slower than graph execution! ```\n",
        "\n",
        "### Graph execution\n",
        "\n",
        "1. Graph execution extracts tensor computations from Python and builds an efficient graph before evaluation. Graphs, or `tf.Graph` objects, are special data structures with `tf.Operation` and `tf.Tensor` objects.\n",
        "2. While `tf.Operation` objects represent computational units, `tf.Tensor` objects represent data units. \n",
        "3. With a graph, you can take advantage of your model in mobile, embedded, and backend environment where Python is unavailable.\n",
        "\n",
        "```  graph execution is ideal for large model training ```\n",
        "\n",
        "``` For small model training, eager execution is better suited. ```\n",
        "\n",
        "<a href=\"https://towardsdatascience.com/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6#:~:text=Eager%20execution%20is,they%20occur%20in%20your%20code\"> Graph executions vs Eager Execution </a>"
      ],
      "metadata": {
        "id": "3W-Z4YJl4KBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qJ5t4YKLJS3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### How does tensorflow work?\n",
        "\n",
        "1. every computation in tensorflow is described as directed graph which is composed of nodes and edges where nodes are composed of operations/functions and edges are the inputs/outputs flowing in or out those functions. \n",
        "\n",
        "2. inputs and outputs in tensorflow are called as tensors. \n",
        "\n",
        "3. before tf 2.0 users need to manually create sessions but after tf 2.0 you dont need to create sessions explicitly. \n",
        "\n",
        "4. whenever you create tensors or write operations the session is automatically invoked and execution graph is created. \n",
        "\n",
        "5. tf.Variable is a mutable tensor which can survive during multiple execution unlike tf.Constant which dies/remains unchanged. \n",
        "\n",
        "6. weights and biases of a model are stored in variables. "
      ],
      "metadata": {
        "id": "zIOANN1K1II3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### tf autograph\n",
        "\n",
        "1.  AutoGraph takes in your eager-style Python code and converts it to graph-generating code.\n",
        "2. autograph converts python code into pure tensorflow graph code. "
      ],
      "metadata": {
        "id": "1qTDMHBV1IM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ` tf.function `\n",
        "\n",
        "1. you can actually build models just like eager execution and then run it with graph execution. And thats what `tf.function` does. \n",
        "2. This simplification is achieved by using `tf.function()` decorators.\n",
        "3. In TensorFlow 2.0, you can decorate a Python function using tf.function() to run it as a single graph object. With this new method, you can easily build models and gain all the graph execution benefits."
      ],
      "metadata": {
        "id": "yph0DzyiBi5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones((2,2))\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  t.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  z = tf.multiply(x, x)\n",
        "\n",
        "dz_dx = t.gradient(z, x)\n",
        "\n",
        "# for i in [0, 1]:\n",
        "#   for j in [0, 1]:"
      ],
      "metadata": {
        "id": "HkwZCag41IQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "  g.watch(x)\n",
        "  y = x**2\n",
        "  z = y**2\n",
        "\n",
        "dz_dx = g.gradient(z, x)\n",
        "dy_dx = g.gradient(y, x)\n",
        "\n",
        "dz_dx.numpy(), dy_dx.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm3UE9o51IUN",
        "outputId": "02e2343e-5244-4f93-c5ed-4fea0c23d3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(10.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "\n",
        "  with tf.GradientTape() as gg:\n",
        "    gg.watch(x)\n",
        "    y = x**2\n",
        "    dy_dx = gg.gradient(y, x)\n",
        "\n",
        "  d2y_dx2 = g.gradient(dy_dx, x)\n",
        "\n",
        "dy_dx.numpy(), d2y_dx2.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1g4VsJw1IYM",
        "outputId": "01418215-a8b6-4f49-b667-0e9d8dabfcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20.0, 2.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)  # trainable parameters are automatically watched if set trainable = True and also tensors can be manually watched if this method\n",
        "              # is invoked in the context manager\n",
        "  y = x**2\n",
        "  dy_dx = g.gradient(y, x)\n",
        "dy_dx.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoGC625P1Icj",
        "outputId": "3168457f-d4c7-4e45-dcad-c459ce5293bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EglhO0eK1Iga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def eager_function(x):\n",
        "\n",
        "  result = x**2\n",
        "  return result\n",
        "\n",
        "l = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)\n",
        "print(eager_function(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBiHLYWZ1IkZ",
        "outputId": "a1c99404-24aa-4042-97de-9f37dd34fde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1.  4.  9. 16. 25.], shape=(5,), dtype=float32)\n",
            "CPU times: user 6.59 ms, sys: 842 µs, total: 7.43 ms\n",
            "Wall time: 9.62 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "graph_func = tf.function(tf.autograph.experimental.do_not_convert(eager_function))\n",
        "print(graph_func(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcS2ogxp1Ioi",
        "outputId": "5352208a-bc88-4001-9d05-3948f5bf52aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 1.  4.  9. 16. 25.], shape=(5,), dtype=float32)\n",
            "CPU times: user 13.4 ms, sys: 0 ns, total: 13.4 ms\n",
            "Wall time: 13.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit"
      ],
      "metadata": {
        "id": "P0KcYLHQE7Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "print(f\"eager function {timeit.timeit(lambda: eager_function(x), number=100)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6ueJRv_1Ir9",
        "outputId": "68beaafe-e33d-4768-9b2f-447a0178fa49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eager function 0.00692260800042277\n",
            "CPU times: user 6.82 ms, sys: 68 µs, total: 6.89 ms\n",
            "Wall time: 8.26 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print(f\"graph execution {timeit.timeit(lambda: graph_func(x), number=100)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCwEp9M-Ew07",
        "outputId": "0dfbc7a4-5c7c-4e0d-c926-2f9fccf7334d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph execution 0.041643855999609514\n",
            "CPU times: user 40.9 ms, sys: 4.18 ms, total: 45.1 ms\n",
            "Wall time: 42.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PO91ImspFTmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.layers.Input(shape=(28, 28))\n",
        "x = keras.layers.Flatten()(inputs)\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "input = tf.random.uniform([100, 28, 28])"
      ],
      "metadata": {
        "id": "NByBX-TCFfd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eager_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "print(f\"eager time: {timeit.timeit(lambda: eager_model(input), number=10000)}\")\n",
        "\n",
        "graph_model = tf.function(eager_model) # wrapping the model with tf.function\n",
        "print(f\"graph time: {timeit.timeit(lambda: graph_model(input), number=10000)}\")"
      ],
      "metadata": {
        "id": "OtZ3ISPaFfia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6d5cce-f294-435f-e9c1-41d758f77b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eager time: 20.07116643399968\n",
            "graph time: 9.569780077999894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0ucvwEWXFfmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones([2,2])\n",
        "\n",
        "print(x.numpy())\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "\n",
        "  t.watch(x)\n",
        "  y = tf.reduce_sum(x)\n",
        "  print(y.numpy())\n",
        "  z = tf.multiply(y, y)\n",
        "  print(z.numpy())\n",
        "  dz_dx = t.gradient(z, x)\n",
        "\n",
        "dz_dx.numpy()"
      ],
      "metadata": {
        "id": "dx5KrrIIFfpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc56d47d-3d31-45e4-da5f-90287c89f9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "4.0\n",
            "16.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8., 8.],\n",
              "       [8., 8.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as t:\n",
        "\n",
        "  t.watch(x)\n",
        "  y = x*x\n",
        "  print(y.numpy())\n",
        "  z = y*y\n",
        "  print(z.numpy())\n",
        "\n",
        "dz_dx = t.gradient(z, x)\n",
        "print(dz_dx.numpy())\n",
        "dy_dx = t.gradient(y, x)\n",
        "print(dy_dx.numpy())"
      ],
      "metadata": {
        "id": "BA5b_Ie5Fftj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c42496-4442-4a9c-efef-18f42c57e978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.0\n",
            "81.0\n",
            "108.0\n",
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as t:\n",
        "  with tf.GradientTape() as t2:\n",
        "    y = x*x*x\n",
        "  dy_dx = t2.gradient(y, x)\n",
        "d2y_dx2 = t.gradient(dy_dx, x)\n",
        "\n",
        "print(dy_dx.numpy())\n",
        "print(d2y_dx2.numpy())"
      ],
      "metadata": {
        "id": "SByzeyLEFfxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f4ff3c-c07c-48a4-b64d-32191515ca07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n",
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def circle_area(r):\n",
        "\n",
        "  circle = 3.14 * (r)**2\n",
        "  return circle"
      ],
      "metadata": {
        "id": "T56n_4kzmZSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.autograph.to_code(circle_area))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3E1_FJumZjY",
        "outputId": "0577ec62-6b3d-49f8-9e86-0620216eb509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__circle_area(r):\n",
            "    with ag__.FunctionScope('circle_area', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        circle = (3.14 * (ag__.ld(r) ** 2))\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = ag__.ld(circle)\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.autograph.to_graph(circle_area))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XwagNLOmZr0",
        "outputId": "7e2ad384-07c1-4892-9e0f-d70f6306cfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function outer_factory.<locals>.inner_factory.<locals>.tf__circle_area at 0x7f211ad5c8c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def circle_area(r):\n",
        "\n",
        "  area = 3.14 * (r)**2\n",
        "  return area"
      ],
      "metadata": {
        "id": "zgskAOPsmZxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.autograph.to_code(circle_area.python_function))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4x8XIKvmZ1m",
        "outputId": "306be5a5-fa73-42f5-da06-15d8df82f8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__circle_area(r):\n",
            "    with ag__.FunctionScope('circle_area', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        area = (3.14 * (ag__.ld(r) ** 2))\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = ag__.ld(area)\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bzWEjbJYmXd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a simple model with Tensorflow and tf.GradientTape()"
      ],
      "metadata": {
        "id": "uFV1pvI-Ff0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "UPvHrhbvSpDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "9KDIuHwJSpHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "GdZ_-MGrSpLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd5aeec-32f3-43fd-9417-4c2b94420e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "gfg4kcfzSpPf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5468b1fb-8b9b-4375-9d08-b6015673ee20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "X_train = X_train/255.0"
      ],
      "metadata": {
        "id": "2kaG_GZcSpTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "Bh0FjbDcSpX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c513515-7ad8-4110-ac49-b77cf3400c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "574nOTsXSpga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcjnQVZiaKST",
        "outputId": "bdafbc9f-8dd8-4dcf-98be-c36f94dde61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "wWWQFrKyjPEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(64)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)"
      ],
      "metadata": {
        "id": "23D6GzbCjK0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2_W38aQV3VEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(16, (3,3), padding=\"same\", input_shape=(28, 28, 1), activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(axis=-1),\n",
        "    keras.layers.Dropout(0.5),\n",
        "\n",
        "    keras.layers.Dense(10, activation=\"softmax\")])"
      ],
      "metadata": {
        "id": "D699QeLw88GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cce_loss = keras.losses.CategoricalCrossentropy()\n",
        "adam = keras.optimizers.Adam()"
      ],
      "metadata": {
        "id": "rA7VhuhhiyaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f\"Epoch {epoch}\")\n",
        "  for step, (X_train, y_train) in enumerate(train_dataset):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      preds = model(X_train, training=True)\n",
        "      loss_val = cce_loss(y_train, preds)\n",
        "\n",
        "    grads = tape.gradient(loss_val, model.trainable_weights)\n",
        "    adam.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "    if step%200==0:\n",
        "      print(f\"Training loss at step {step} = {np.round(loss_val, 3)}\")\n",
        "      print(f\"Samples seen so far = {(step+1)*64}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XijluhxjErT",
        "outputId": "9c80652b-02bb-4364-c91e-82da56c26e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Training loss at step 0 = 3.5339999198913574\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.11999999731779099\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.15399999916553497\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.05299999937415123\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.10100000351667404\n",
            "Samples seen so far = 51264\n",
            "Epoch 1\n",
            "Training loss at step 0 = 0.16599999368190765\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.03200000151991844\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.010999999940395355\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.06199999898672104\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.12700000405311584\n",
            "Samples seen so far = 51264\n",
            "Epoch 2\n",
            "Training loss at step 0 = 0.013000000268220901\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.009999999776482582\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.010999999940395355\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.052000001072883606\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.07599999755620956\n",
            "Samples seen so far = 51264\n",
            "Epoch 3\n",
            "Training loss at step 0 = 0.0430000014603138\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.017999999225139618\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.01600000075995922\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.0020000000949949026\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.013000000268220901\n",
            "Samples seen so far = 51264\n",
            "Epoch 4\n",
            "Training loss at step 0 = 0.0689999982714653\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.04500000178813934\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.0020000000949949026\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.007000000216066837\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.05000000074505806\n",
            "Samples seen so far = 51264\n",
            "Epoch 5\n",
            "Training loss at step 0 = 0.11400000005960464\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.00800000037997961\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.004000000189989805\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.023000000044703484\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.03200000151991844\n",
            "Samples seen so far = 51264\n",
            "Epoch 6\n",
            "Training loss at step 0 = 0.024000000208616257\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.03099999949336052\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.020999999716877937\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.0020000000949949026\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.09099999815225601\n",
            "Samples seen so far = 51264\n",
            "Epoch 7\n",
            "Training loss at step 0 = 0.017999999225139618\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.08699999749660492\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.03500000014901161\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.03500000014901161\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.00800000037997961\n",
            "Samples seen so far = 51264\n",
            "Epoch 8\n",
            "Training loss at step 0 = 0.003000000026077032\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.00800000037997961\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.006000000052154064\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.0020000000949949026\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.004999999888241291\n",
            "Samples seen so far = 51264\n",
            "Epoch 9\n",
            "Training loss at step 0 = 0.0010000000474974513\n",
            "Samples seen so far = 64\n",
            "Training loss at step 200 = 0.028999999165534973\n",
            "Samples seen so far = 12864\n",
            "Training loss at step 400 = 0.0010000000474974513\n",
            "Samples seen so far = 25664\n",
            "Training loss at step 600 = 0.013000000268220901\n",
            "Samples seen so far = 38464\n",
            "Training loss at step 800 = 0.00800000037997961\n",
            "Samples seen so far = 51264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def step(X, y):\n",
        "\n",
        "#   # keep track of gradients\n",
        "#   with tf.GradientTape() as tape:\n",
        "#     # make a prediction using the model and calculate the loss\n",
        "#     pred = model(X)\n",
        "#     loss = cce(y, pred)\n",
        "    \n",
        "#   print(f\"Loss = {loss}\")\n",
        "\n",
        "#   # calculate the gradients using tape and update the model weights\n",
        "#   grads = tape.gradient(loss, model.trainable_variables)\n",
        "#   opt.apply_gradients(zip(grads, model.trainable_variables))"
      ],
      "metadata": {
        "id": "f8U6MFEEA-4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = build_model(28, 28, 1, 10)"
      ],
      "metadata": {
        "id": "HY3Bm0OxBagx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_updates = int(X_train.shape[0]/64)  # bqtch size = 64\n",
        "\n",
        "# for epoch in range(1, 20+1):\n",
        "#   # show the current epoch number\n",
        "#   epoch_start = time.time()\n",
        "#   print(f\"The current epoch is {epoch}\")\n",
        "\n",
        "#   for x in range(0, num_updates):\n",
        "#     start = x*64\n",
        "#     end = start+64\n",
        "\n",
        "#     step(X_train[start:end], y_train[start:end])\n",
        "\n",
        "#   epoch_end = time.time()\n",
        "#   print(f\"took {(epoch_end - epoch_start)} seconds\")"
      ],
      "metadata": {
        "id": "WAChgDK0BakQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=cce_loss, optimizer=adam, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ka0DM-bvBan7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cTc_uIJBaq3",
        "outputId": "b670466f-77c9-44f3-a171-6b9e40349cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0371 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0371207594871521, 0.9887999892234802]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qgcgAnzlh-EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### tf distributed training\n",
        "\n",
        "1. distribution is not automatic\n",
        "\n",
        "there are two algorithms for distributed training\n",
        "1. data parallelism\n",
        "2. model parallelism\n",
        "\n",
        "`model parallelism` works best for models where there are independent parts of computation that you can run in parallel. in other words, putting different layers of the model on different machines \n",
        "\n",
        "`data parallelism` works best for any model architecture which makes it much more widely adopted for distributed training. the main idea in data parallelism is that with more gpus your model would be able to see more data on each training step which means it will take less time to finish an epoch. \n",
        "\n",
        "      model.fit(X, y, batch_size=(32*num_gpus)) \n",
        "      # in this case each gpu gets a slice of the data, the gradients are updated and then those gradients are averaged.\n",
        "\n"
      ],
      "metadata": {
        "id": "FviK5OsAVVyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BMzfPKkoVV16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cf0rBArkVV5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "prO_sHqaVV87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WpLRUQlQVWAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ibZfrYHwVWEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R-nU_gzGVWH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j0DMosIGVWK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}